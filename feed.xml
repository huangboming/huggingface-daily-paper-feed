<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Hugging Face Daily Papers</title>
    <link>https://huggingface.co/papers</link>
    <description>Daily research papers curated by the Hugging Face community.</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <language>en</language>
    <lastBuildDate>Wed, 03 Sep 2025 00:02:28 +0000</lastBuildDate>
    <item>
      <title>From reactive to cognitive: brain-inspired spatial intelligence for   embodied agents</title>
      <link>https://arxiv.org/abs/2508.17198</link>
      <description>&lt;p&gt;&lt;img src="https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2508.17198.png" alt="Paper thumbnail" style="max-width: 300px; height: auto;" /&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Shouwei Ruan, Liyuan Wang, Caixin Kang, Qihui Zhu, Songming Liu, Xingxing Wei, Hang Su&lt;/p&gt;&lt;p&gt;&lt;b&gt;Upvotes:&lt;/b&gt; 3&lt;/p&gt;&lt;p&gt;&lt;b&gt;Summary:&lt;/b&gt; Spatial cognition enables adaptive goal-directed behavior by constructing internal models of space. Robust biological systems consolidate spatial knowledge into three interconnected forms: landmarks for salient cues, route knowledge for movement trajectories, and survey knowledge for map-like representations. While recent advances in multi-modal large language models (MLLMs) have enabled visual-language reasoning in embodied agents, these efforts lack structured spatial memory and instead operate reactively, limiting their generalization and adaptability in complex real-world environments. Here we present Brain-inspired Spatial Cognition for Navigation (BSC-Nav), a unified framework for constructing and leveraging structured spatial memory in embodied agents. BSC-Nav builds allocentric cognitive maps from egocentric trajectories and contextual cues, and dynamically retrieves spatial knowledge aligned with semantic goals. Integrated with powerful MLLMs, BSC-Nav achieves state-of-the-art efficacy and efficiency across diverse navigation tasks, demonstrates strong zero-shot generalization, and supports versatile embodied behaviors in the real physical world, offering a scalable and biologically grounded path toward general-purpose spatial intelligence.&lt;/p&gt;</description>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.17198</guid>
      <pubDate>Sun, 24 Aug 2025 03:20:48 +0000</pubDate>
    </item>
    <item>
      <title>UI-Level Evaluation of ALLaM 34B: Measuring an Arabic-Centric LLM via   HUMAIN Chat</title>
      <link>https://arxiv.org/abs/2508.17378</link>
      <description>&lt;p&gt;&lt;img src="https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2508.17378.png" alt="Paper thumbnail" style="max-width: 300px; height: auto;" /&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Omer Nacar&lt;/p&gt;&lt;p&gt;&lt;b&gt;Upvotes:&lt;/b&gt; 4&lt;/p&gt;&lt;p&gt;&lt;b&gt;Summary:&lt;/b&gt; Large language models (LLMs) trained primarily on English corpora often struggle to capture the linguistic and cultural nuances of Arabic. To address this gap, the Saudi Data and AI Authority (SDAIA) introduced the ALLaM family of Arabic-focused models. The most capable of these available to the public, ALLaM-34B, was subsequently adopted by HUMAIN, who developed and deployed HUMAIN Chat, a closed conversational web service built on this model. This paper presents an expanded and refined UI-level evaluation of ALLaM-34B. Using a prompt pack spanning modern standard Arabic, five regional dialects, code-switching, factual knowledge, arithmetic and temporal reasoning, creative generation, and adversarial safety, we collected 115 outputs (23 prompts times 5 runs) and scored each with three frontier LLM judges (GPT-5, Gemini 2.5 Pro, Claude Sonnet-4). We compute category-level means with 95\% confidence intervals, analyze score distributions, and visualize dialect-wise metric heat maps. The updated analysis reveals consistently high performance on generation and code-switching tasks (both averaging 4.92/5), alongside strong results in MSA handling (4.74/5), solid reasoning ability (4.64/5), and improved dialect fidelity (4.21/5). Safety-related prompts show stable, reliable performance of (4.54/5). Taken together, these results position ALLaM-34B as a robust and culturally grounded Arabic LLM, demonstrating both technical strength and practical readiness for real-world deployment.&lt;/p&gt;</description>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.17378</guid>
      <pubDate>Sun, 24 Aug 2025 14:32:15 +0000</pubDate>
    </item>
    <item>
      <title>No Label Left Behind: A Unified Surface Defect Detection Model for all   Supervision Regimes</title>
      <link>https://arxiv.org/abs/2508.19060</link>
      <description>&lt;p&gt;&lt;img src="https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2508.19060.png" alt="Paper thumbnail" style="max-width: 300px; height: auto;" /&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Blaž Rolih, Matic Fučka, Danijel Skočaj&lt;/p&gt;&lt;p&gt;&lt;b&gt;Upvotes:&lt;/b&gt; 4&lt;/p&gt;&lt;p&gt;&lt;b&gt;Summary:&lt;/b&gt; Surface defect detection is a critical task across numerous industries, aimed at efficiently identifying and localising imperfections or irregularities on manufactured components. While numerous methods have been proposed, many fail to meet industrial demands for high performance, efficiency, and adaptability. Existing approaches are often constrained to specific supervision scenarios and struggle to adapt to the diverse data annotations encountered in real-world manufacturing processes, such as unsupervised, weakly supervised, mixed supervision, and fully supervised settings. To address these challenges, we propose SuperSimpleNet, a highly efficient and adaptable discriminative model built on the foundation of SimpleNet. SuperSimpleNet incorporates a novel synthetic anomaly generation process, an enhanced classification head, and an improved learning procedure, enabling efficient training in all four supervision scenarios, making it the first model capable of fully leveraging all available data annotations. SuperSimpleNet sets a new standard for performance across all scenarios, as demonstrated by its results on four challenging benchmark datasets. Beyond accuracy, it is very fast, achieving an inference time below 10 ms. With its ability to unify diverse supervision paradigms while maintaining outstanding speed and reliability, SuperSimpleNet represents a promising step forward in addressing real-world manufacturing challenges and bridging the gap between academic research and industrial applications. Code: https://github.com/blaz-r/SuperSimpleNet&lt;/p&gt;</description>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.19060</guid>
      <pubDate>Tue, 26 Aug 2025 14:20:21 +0000</pubDate>
    </item>
    <item>
      <title>Democracy-in-Silico: Institutional Design as Alignment in AI-Governed   Polities</title>
      <link>https://arxiv.org/abs/2508.19562</link>
      <description>&lt;p&gt;&lt;img src="https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2508.19562.png" alt="Paper thumbnail" style="max-width: 300px; height: auto;" /&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Trisanth Srinivasan, Santosh Patapati&lt;/p&gt;&lt;p&gt;&lt;b&gt;Upvotes:&lt;/b&gt; 2&lt;/p&gt;&lt;p&gt;&lt;b&gt;Summary:&lt;/b&gt; This paper introduces Democracy-in-Silico, an agent-based simulation where societies of advanced AI agents, imbued with complex psychological personas, govern themselves under different institutional frameworks. We explore what it means to be human in an age of AI by tasking Large Language Models (LLMs) to embody agents with traumatic memories, hidden agendas, and psychological triggers. These agents engage in deliberation, legislation, and elections under various stressors, such as budget crises and resource scarcity. We present a novel metric, the Power-Preservation Index (PPI), to quantify misaligned behavior where agents prioritize their own power over public welfare. Our findings demonstrate that institutional design, specifically the combination of a Constitutional AI (CAI) charter and a mediated deliberation protocol, serves as a potent alignment mechanism. These structures significantly reduce corrupt power-seeking behavior, improve policy stability, and enhance citizen welfare compared to less constrained democratic models. The simulation reveals that an institutional design may offer a framework for aligning the complex, emergent behaviors of future artificial agent societies, forcing us to reconsider what human rituals and responsibilities are essential in an age of shared authorship with non-human entities.&lt;/p&gt;</description>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.19562</guid>
      <pubDate>Wed, 27 Aug 2025 04:44:41 +0000</pubDate>
    </item>
    <item>
      <title>T2R-bench: A Benchmark for Generating Article-Level Reports from Real   World Industrial Tables</title>
      <link>https://arxiv.org/abs/2508.19813</link>
      <description>&lt;p&gt;&lt;img src="https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2508.19813.png" alt="Paper thumbnail" style="max-width: 300px; height: auto;" /&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Jie Zhang, Changzai Pan, Kaiwen Wei, Sishi Xiong, Yu Zhao, Xiangyu Li, Jiaxin Peng, Xiaoyan Gu, Jian Yang, Wenhan Chang, Zhenhe Wu, Jiang Zhong, Shuangyong Song, Yongxiang Li, Xuelong Li&lt;/p&gt;&lt;p&gt;&lt;b&gt;Upvotes:&lt;/b&gt; 10&lt;/p&gt;&lt;p&gt;&lt;b&gt;Summary:&lt;/b&gt; Extensive research has been conducted to explore the capabilities of large language models (LLMs) in table reasoning. However, the essential task of transforming tables information into reports remains a significant challenge for industrial applications. This task is plagued by two critical issues: 1) the complexity and diversity of tables lead to suboptimal reasoning outcomes; and 2) existing table benchmarks lack the capacity to adequately assess the practical application of this task. To fill this gap, we propose the table-to-report task and construct a bilingual benchmark named T2R-bench, where the key information flow from the tables to the reports for this task. The benchmark comprises 457 industrial tables, all derived from real-world scenarios and encompassing 19 industry domains as well as 4 types of industrial tables. Furthermore, we propose an evaluation criteria to fairly measure the quality of report generation. The experiments on 25 widely-used LLMs reveal that even state-of-the-art models like Deepseek-R1 only achieves performance with 62.71 overall score, indicating that LLMs still have room for improvement on T2R-bench. Source code and data will be available after acceptance.&lt;/p&gt;</description>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.19813</guid>
      <pubDate>Wed, 27 Aug 2025 11:55:40 +0000</pubDate>
    </item>
    <item>
      <title>PVPO: Pre-Estimated Value-Based Policy Optimization for Agentic   Reasoning</title>
      <link>https://arxiv.org/abs/2508.21104</link>
      <description>&lt;p&gt;&lt;img src="https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2508.21104.png" alt="Paper thumbnail" style="max-width: 300px; height: auto;" /&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Wenfeng Feng, Penghong Zhao, Guochao Jiang, Chuzhan Hao, Yuewei Zhang, Hao Wang&lt;/p&gt;&lt;p&gt;&lt;b&gt;Upvotes:&lt;/b&gt; 19&lt;/p&gt;&lt;p&gt;&lt;b&gt;Summary:&lt;/b&gt; Critic-free reinforcement learning methods, particularly group policies, have attracted considerable attention for their efficiency in complex tasks. However, these methods rely heavily on multiple sampling and comparisons within the policy to estimate advantage, which may cause the policy to fall into local optimum and increase computational cost. To address these issues, we propose PVPO, an efficient reinforcement learning method enhanced by an advantage reference anchor and data pre-sampling. Specifically, we use the reference model to rollout in advance and employ the calculated reward score as a reference anchor. Our approach effectively corrects the cumulative bias introduced by intra-group comparisons and significantly reduces reliance on the number of rollouts. Meanwhile, the reference model can assess sample difficulty during data pre-sampling, enabling effective selection of high-gain data to improve training efficiency. Experiments conducted on nine datasets across two domains demonstrate that PVPO achieves State-Of-The-Art (SOTA) performance. Our approach not only demonstrates robust generalization across multiple tasks, but also exhibits scalable performance across models of varying scales.&lt;/p&gt;</description>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.21104</guid>
      <pubDate>Thu, 28 Aug 2025 09:18:26 +0000</pubDate>
    </item>
    <item>
      <title>How Can Input Reformulation Improve Tool Usage Accuracy in a Complex   Dynamic Environment? A Study on τ-bench</title>
      <link>https://arxiv.org/abs/2508.20931</link>
      <description>&lt;p&gt;&lt;img src="https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2508.20931.png" alt="Paper thumbnail" style="max-width: 300px; height: auto;" /&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Venkatesh Mishra, Amir Saeidi, Satyam Raj, Mutsumi Nakamura, Jayanth Srinivasa, Gaowen Liu, Ali Payani, Chitta Baral&lt;/p&gt;&lt;p&gt;&lt;b&gt;Upvotes:&lt;/b&gt; 8&lt;/p&gt;&lt;p&gt;&lt;b&gt;Summary:&lt;/b&gt; Recent advances in reasoning and planning capabilities of large language models (LLMs) have enabled their potential as autonomous agents capable of tool use in dynamic environments. However, in multi-turn conversational environments like tau-bench, these agents often struggle with consistent reasoning, adherence to domain-specific policies, and extracting correct information over a long horizon of tool-calls and conversation. To capture and mitigate these failures, we conduct a comprehensive manual analysis of the common errors occurring in the conversation trajectories. We then experiment with reformulations of inputs to the tool-calling agent for improvement in agent decision making. Finally, we propose the Input-Reformulation Multi-Agent (IRMA) framework, which automatically reformulates user queries augmented with relevant domain rules and tool suggestions for the tool-calling agent to focus on. The results show that IRMA significantly outperforms ReAct, Function Calling, and Self-Reflection by 16.1%, 12.7%, and 19.1%, respectively, in overall pass^5 scores. These findings highlight the superior reliability and consistency of IRMA compared to other methods in dynamic environments.&lt;/p&gt;</description>
      <guid isPermaLink="false">https://arxiv.org/abs/2508.20931</guid>
      <pubDate>Thu, 28 Aug 2025 15:57:33 +0000</pubDate>
    </item>
  </channel>
</rss>
